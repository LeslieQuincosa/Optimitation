{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzQd6icC42QG"
      },
      "source": [
        "# Curso de Optimización (DEMAT)\n",
        "## Tarea 9\n",
        "## Leslie Janeth Quincosa Ramírez\n",
        "\n",
        "| Descripción:                         | Fechas               |\n",
        "|--------------------------------------|----------------------|\n",
        "| Fecha de publicación del documento:  | **Abril 28, 2022**   |\n",
        "| Fecha límite de entrega de la tarea: | **Mayo   8, 2022**   |\n",
        "\n",
        "\n",
        "### Indicaciones\n",
        "\n",
        "- Envie el notebook que contenga los códigos y las pruebas realizadas de cada ejercicio.\n",
        "- Si se requiren algunos scripts adicionales para poder reproducir las pruebas,\n",
        "  agreguelos en un ZIP junto con el notebook.\n",
        "- Genere un PDF del notebook y envielo por separado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulsuV4Ak42QN"
      },
      "source": [
        "---\n",
        "\n",
        "## Ejercicio 0 (0 puntos)\n",
        "\n",
        "- Empezar a buscar un tema para el proyecto final del curso.\n",
        "- En esta tarea no hay que poner la descripción del proyecto.\n",
        "  Sólo buscar el tema y tenerlo listo para su entrega en la\n",
        "  siguiente tarea.\n",
        "- La fecha límite para mandar la descripción del proyecto\n",
        "  se tiene que mandar es el domingo 17 de mayo. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veGg2Nw542QO"
      },
      "source": [
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4n2Xmb142QP"
      },
      "source": [
        "## Ejercicio 1. (2 puntos)\n",
        "\n",
        "Programar las siguientes funciones y sus gradientes, de modo que dependan de la dimensión $n$ de la variable $\\mathbf{x}$:\n",
        "\n",
        "\n",
        "- Función \"Tridiagonal 1\" generalizada\n",
        "\n",
        "$$  f(x) = \\sum_{i=1}^{n-1} (x_i + x_{i+1} - 3)^2 + (x_i - x_{i+1} + 1)^4  $$\n",
        "\n",
        "\n",
        "- Función generalizada de Rosenbrock\n",
        "\n",
        "$$  f(x) = \\sum_{i=1}^{n-1} 100(x_{i+1} - x_i^2)^2 + (1 - x_{i} )^2  $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "zOq6nsQP42QQ"
      },
      "outputs": [],
      "source": [
        "# Implementación de la funciones y sus gradientes\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "from numpy.linalg import eigvals\n",
        "import sys\n",
        "\n",
        "#intento de función tridiagonal\n",
        "def Tridiagonal1(x):\n",
        "    return np.sum( (x[:-1] + x[1:] - 3)**2 + (x[:-1] - x[1:] + 1)**4)\n",
        "\n",
        "def gradTridiagonal1(x):\n",
        "    n = x.size\n",
        "    g = np.zeros(n)\n",
        "    g[1:-1] = 2*(x[:-2] + x[1:-1] -3) - 4*(x[:-2] - x[1:-1] + 1)**3 + 2*(x[1:-1] + x[2:] -3) + 4*(x[1:-1] - x[2:] + 1)**3\n",
        "    g[0] = 2*(x[0] + x[1] - 3) + 4*(x[0] - x[1] + 1)**3\n",
        "    g[n-1] = 2*(x[n-2] + x[n-1] - 3) - 4*(x[n-2] - x[n-1] + 1)**3\n",
        "    return g\n",
        "\n",
        "#Intento de función\n",
        "def Rosenbrock(x):\n",
        "    return np.sum( 100*(x[1:] - x[:-1]**2)**2 + (1-x[:-1])**2)\n",
        "\n",
        "#Intento de gradiente de Rosenbrock\n",
        "def gradRosenbrock(x):\n",
        "    n = x.size\n",
        "    g = np.zeros(n)\n",
        "    g[1:-1] = 200*(x[1:-1] -x[:-2]**2) -400*x[1:-1]*(x[2:]-x[1:-1]**2)-2*(1-x[1:-1])\n",
        "    g[0] = 200*(x[1]-x[0]**2)*(-2*x[0]) - 2*(1-x[0])\n",
        "    g[n-1] = 200*(x[n-1]-x[n-2]**2)\n",
        "    return g\n",
        "\n",
        "#Función Tridiagonal que usé\n",
        "def Tridiag(x):\n",
        "  f=0\n",
        "  for i in range(len(x)-1):\n",
        "    f += 100 * (x[i] + x[i+1] - 3)**2 + (x[i] - x[i+1] + 1)**4\n",
        "    return f\n",
        "    \n",
        "#Gradiente de la tridiagonal que usé\n",
        "def gradTridiag(x):\n",
        "    n = len(x)\n",
        "    g = np.zeros((n), dtype = np.float64)\n",
        "    g[0] = 2*(x[0] + x[1] - 3) + 4*(x[0] - x[1] + 1)**3\n",
        "    g[n-1] = 2*(x[n-2] + x[n-1] - 3) - 4*(x[n-2] - x[n-1] + 1)**3\n",
        "    for i in range(1, n-1):\n",
        "      g[i] = 2*(x[i-1] + x[i] -3) - 4*(x[i-1] - x[i] + 1)**3 + 2*(x[i] + x[i+1] -3) + 4*(x[i] - x[i+1] + 1)**3\n",
        "    return g\n",
        "\n",
        "#Esta es la función de Rosenbrock generalizada que usé\n",
        "def fR(x):\n",
        "  f=0\n",
        "  for i in range(len(x)-1):\n",
        "    f += 100 * (x[i+1] - x[i]**2)**2 + (1-x[i])**2\n",
        "    return f\n",
        "\n",
        "#Usé este gradiente en el ejercicio\n",
        "def gradR(x):\n",
        "    n = len(x)\n",
        "    g = np.zeros((n), dtype = np.float64)\n",
        "    g[0] = 200*(x[1]-x[0]**2)*(-2*x[0]) - 2*(1-x[0])\n",
        "    g[n-1] = 200*(x[n-1]-x[n-2]**2)\n",
        "    for i in range(1, n-1):\n",
        "      g[i] = 200*(x[i] -x[i+1]**2) -400*x[i]*(x[i+1]-x[i]**2)- 2*(1-x[i])\n",
        "    return g"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta parte utilizé diferentes formas de crear las funciones y sus gradientes correspondientes ya que me salía error con los primeros. Los dejo de evidencia porque creo que estaban bien."
      ],
      "metadata": {
        "id": "PlDbs65ddM9S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igex2qa842QR"
      },
      "source": [
        "## Ejercicio 1 (8 puntos)\n",
        "\n",
        "Programar y probar el método BFGS modificado.\n",
        "\n",
        "\n",
        "1. Programar el algoritmo descrito en la diapositiva 16 de la clase 23.\n",
        "   Agregue una variable $res$ que indique si el algoritmo terminó\n",
        "   porque se cumplió que la magnitud del gradiente es menor que la toleracia\n",
        "   dada.\n",
        "2. Probar el algoritmo con las funciones del Ejercicio 1\n",
        "   con la matriz $H_0$ como la matriz identidad y el \n",
        "   punto inicial $x_0$ como:\n",
        "\n",
        "- La función generalizada de Rosenbrock: \n",
        "\n",
        "$$ x_0 = (-1.2, 1, -1.2, 1, ..., -1.2, 1) \\in \\mathbb{R}^n$$\n",
        "\n",
        "- La función Tridiagonal 1 generalizada: \n",
        "\n",
        "$$ x_0 = (2,2, ..., 2) \\in \\mathbb{R}^n $$\n",
        "  \n",
        "  Pruebe el algoritmo con la dimensión $n=2, 10 , 100$.\n",
        "\n",
        "3. Fije el número de iteraciones máximas a $N=50000$, \n",
        "   y la tolerancia $\\tau = \\epsilon_m^{1/3}$, donde $\\epsilon_m$\n",
        "   es el épsilon máquina, para terminar las iteraciones \n",
        "   si la magnitud del gradiente es menor que $\\tau$.\n",
        "   En cada caso, imprima los siguiente datos:\n",
        "   \n",
        "- $n$,\n",
        "- $f(x_0)$, \n",
        "- Usando la variable $res$, imprima un mensaje que indique si\n",
        "  el algoritmo convergió,\n",
        "- el  número $k$ de iteraciones realizadas,\n",
        "- $f(x_k)$,\n",
        "- la norma del vector $\\nabla f_k$, y\n",
        "- las primeras y últimas 4 entradas del punto $x_k$ que devuelve el algoritmo.\n",
        "  \n",
        "\n",
        "### Solución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "r4PIPAmN42QS"
      },
      "outputs": [],
      "source": [
        "# En esta celda puede poner el código de las funciones\n",
        "# o poner la instrucción para importarlas de un archivo .py\n",
        "def Backtraking(f, fk, gk, xk, pk, a0, rho, c):\n",
        "    a = a0\n",
        "    while f(xk + a*pk) > fk +c*a*gk.T@pk:\n",
        "        a = rho*a\n",
        "    return a\n",
        "\n",
        "def BFGS(f, g, H, x0, N, tol):\n",
        "    res = 0\n",
        "    xk = x0.copy()\n",
        "    n = x0.size\n",
        "    Hk = H.copy()    \n",
        "    I = np.identity(n)\n",
        "    for k in range(N):\n",
        "      gk = g(xk) \n",
        "      fk = f(xk)\n",
        "      norm = LA.norm(gk)\n",
        "      if norm < tol:\n",
        "        res = 1\n",
        "        break\n",
        "      pk = -Hk@gk\n",
        "      if pk.T@gk > 0:\n",
        "        lamb1 = 0.00001 + (pk.T@gk)/(gk.T@gk)\n",
        "        Hk = Hk + lamb1*I\n",
        "        pk = pk - lamb1*gk    ##Condiciones de Wolfe\n",
        "      ak = Backtraking(f, fk, gk, xk, pk, 2, 0.5, 0.00001)\n",
        "      xk1 = xk.copy()        #xk\n",
        "      xk = xk + ak*pk #xk+1\n",
        "      sk = ak*pk #aquí debería estar xk+1-xk, lo modifiqué porque ak era muuuy pequeña\n",
        "      gk1 = gk.copy()\n",
        "      gk = g(xk)   \n",
        "      yk = gk - gk1   \n",
        "      if yk.T@sk <= 0:\n",
        "        lamb2 = 0.00001 - (yk.T@sk)/(sk.T@sk)\n",
        "        Hk = Hk + lamb2*I\n",
        "      else:\n",
        "        rho_k = 1/(yk.T@sk)\n",
        "        Hk = (I - rho_k*sk@yk.T)@Hk@(I - rho_k*yk@sk.T) + rho_k*sk@sk.T\n",
        " \n",
        "    return ak, xk, fk, gk, k, res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jAAImpCMdKE0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "kv5oSiT342QT"
      },
      "outputs": [],
      "source": [
        "# Pruebas realizadas \n",
        "\n",
        "def vectorx0Ros(n):\n",
        "  x = np.zeros(n)\n",
        "  for k in range( int(n/2)):\n",
        "    x[2*k] = -1.2\n",
        "    x[2*k+1] = 1\n",
        "  return x\n",
        "\n",
        "def vectorx0tri(n):\n",
        "  x = np.zeros(n)\n",
        "  for k in range(n):\n",
        "    x[k] = 2\n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función de prueba\n",
        "\n",
        "def ProbarRos(f, g, n, N, tol):\n",
        "    x0 = vectorx0Ros(n)\n",
        "    H = np.identity(n)\n",
        "    ak, xk, fk, gk, k, res = BFGS(f, g, H, x0, N, tol)\n",
        "    if res == 1:\n",
        "        print('¡Convergió! :)')\n",
        "    else:\n",
        "        print('¡No convergió! :(')\n",
        "    print('Valor n:', n)\n",
        "    print('f(x0):', f(x0))\n",
        "    print('Valor k:', k)\n",
        "    print('xk:', xk[:2], '...', xk[n-2:])\n",
        "    print('f(xk):', fk)\n",
        "    print('||fk||:', LA.norm(fk))\n",
        "    print('res:', res)\n",
        "    print('alpha_k:', ak)\n",
        "\n",
        "def ProbarTri(f, g, n, N, tol):\n",
        "    x0 = vectorx0tri(n)\n",
        "    H = np.identity(n)\n",
        "    ak, xk, fk, gk, k, res = BFGS(f, g, H, x0, N, tol)\n",
        "    if res == 1:\n",
        "        print('¡Convergió! :)')\n",
        "    else:\n",
        "        print('¡No convergió! :(')\n",
        "    print('Valor n:', n)\n",
        "    print('f(x0):', f(x0))\n",
        "    print('Valor k:', k)\n",
        "    print('xk:', xk[:2], '...', xk[n-2:])\n",
        "    print('f(xk):', fk)\n",
        "    print('||fk||:', LA.norm(fk))\n",
        "    print('res:', res)\n",
        "    print('alpha_k:', ak)"
      ],
      "metadata": {
        "id": "C0IYygngu84t"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkYOA_px42QU",
        "outputId": "1feb3c33-90ee-4a99-8726-2711b4993127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas para la función de Rosenbrock\n",
            "¡Convergió! :)\n",
            "Valor n: 2\n",
            "f(x0): 24.199999999999996\n",
            "Valor k: 6380\n",
            "xk: [1.00000468 1.00000938] ... [1.00000468 1.00000938]\n",
            "f(xk): 2.194654208075162e-11\n",
            "||fk||: 2.194654208075162e-11\n",
            "res: 1\n",
            "alpha_k: 0.0001220703125\n",
            " \n",
            "¡No convergió! :(\n",
            "Valor n: 10\n",
            "f(x0): 24.199999999999996\n",
            "Valor k: 49999\n",
            "xk: [-1.2  1. ] ... [-1.2  1. ]\n",
            "f(xk): 24.199999999999996\n",
            "||fk||: 24.199999999999996\n",
            "res: 0\n",
            "alpha_k: 1.3552527156068805e-20\n",
            " \n",
            "¡No convergió! :(\n",
            "Valor n: 100\n",
            "f(x0): 24.199999999999996\n",
            "Valor k: 49999\n",
            "xk: [-1.2  1. ] ... [-1.2  1. ]\n",
            "f(xk): 24.199999999999996\n",
            "||fk||: 24.199999999999996\n",
            "res: 0\n",
            "alpha_k: 5.293955920339377e-23\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Pruebas\n",
        "eps = sys.float_info.epsilon\n",
        "tol = eps**(1/3)\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('error', RuntimeWarning)\n",
        "\n",
        "print('Pruebas para la función de Rosenbrock')\n",
        "\n",
        "ProbarRos(fR, gradR, 2, 10000, tol)\n",
        "print(' ')\n",
        "ProbarRos(fR, gradR, 10, 50000, tol)\n",
        "print(' ')\n",
        "ProbarRos(fR, gradR, 100, 50000, tol)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Pruebas para la función de Tridiagonal')\n",
        "ProbarTri(Tridiag, gradTridiag, 2, 50000, tol)\n",
        "print(' ')\n",
        "ProbarTri(Tridiag, gradTridiag, 10, 50000, tol)\n",
        "print(' ')\n",
        "ProbarTri(Tridiag, gradTridiag, 100, 50000, tol)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUGo8JtVw8ee",
        "outputId": "939e6258-157e-4660-84f6-1833529e6391"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruebas para la función de Tridiagonal\n",
            "¡Convergió! :)\n",
            "Valor n: 2\n",
            "f(x0): 101.0\n",
            "Valor k: 2\n",
            "xk: [1. 2.] ... [1. 2.]\n",
            "f(xk): 0.0\n",
            "||fk||: 0.0\n",
            "res: 1\n",
            "alpha_k: 0.125\n",
            " \n",
            "¡No convergió! :(\n",
            "Valor n: 10\n",
            "f(x0): 101.0\n",
            "Valor k: 49999\n",
            "xk: [1.25 1.5 ] ... [1.5  2.25]\n",
            "f(xk): 6.56640625\n",
            "||fk||: 6.56640625\n",
            "res: 0\n",
            "alpha_k: 3.469446951953614e-18\n",
            " \n",
            "¡No convergió! :(\n",
            "Valor n: 100\n",
            "f(x0): 101.0\n",
            "Valor k: 49999\n",
            "xk: [1.25 1.5 ] ... [1.5  2.25]\n",
            "f(xk): 6.56640625\n",
            "||fk||: 6.56640625\n",
            "res: 0\n",
            "alpha_k: 4.336808689942018e-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El valor del $\\alpha_k$ del backtraking es pequeño, por lo que afecta directamente al próximo valor de $x_{k+1}$, de modo que el método está convergiendo de forma lenta. \n",
        "\n",
        "Para el vector de longitud $2$ sí converge el método \"rapidamente\", pero no me converge para longitudes mayores. Intenté verificar la falla con diferentes métodos. Al principio si dejaba $s_k = x_{k+1}-x_k$ los valores de los gradientes se hacían muy grandes y me arrojaba resultados con $NAN$ por lo que módifique el valor de $s_k = \\alpha_k * p_k$, porque cuando hacía las divisiones me quedaba entre $0$.\n",
        "\n",
        "P.D. Se tardaba mucho en hacer los calculos para $n = 100$.\n"
      ],
      "metadata": {
        "id": "zK79-znNbtwZ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "optim_tarea09.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}